{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "Infer from a cosmological model via MCMC samplers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/feynman/work/dphp/hs276503/envs/montenvtest3/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ./src/montecosmo/tests/infer_model.ipynb to script\n",
      "[NbConvertApp] Writing 10505 bytes to src/montecosmo/tests/infer_model.py\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os; os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='1.' # NOTE: jax preallocates GPU (default 75%)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax import numpy as jnp, random as jr, config as jconfig, jit, vmap, grad, debug, tree\n",
    "# jconfig.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from functools import partial\n",
    "from getdist import plots\n",
    "from numpyro import infer\n",
    "\n",
    "from montecosmo.model import FieldLevelModel, default_config\n",
    "from montecosmo.utils import pdump, pload\n",
    "from montecosmo.mcbench import sample_and_save\n",
    "from montecosmo.script import from_id, get_mcmc, get_init_mcmc\n",
    "\n",
    "# import mlflow\n",
    "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8081\")\n",
    "# mlflow.set_experiment(\"infer\")\n",
    "# !jupyter nbconvert --to script ./src/montecosmo/tests/infer_model.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config and fiduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLURM_ARRAY_TASK_ID: 3150\n",
      "save path: /feynman/home/dphp/hs276503/scratch/pickles/m64_b320.0_al0.5_ao0.5_lo1_pc5_obfield/sNUTS_nc4_ns64_mt10_ta0.65\n"
     ]
    }
   ],
   "source": [
    "################## TO SET #######################\n",
    "# task_id = int(os.environ['SLURM_ARRAY_TASK_ID'])\n",
    "task_id = 3150\n",
    "print(\"SLURM_ARRAY_TASK_ID:\", task_id)\n",
    "model, mcmc_config, save_dir, save_path = from_id(task_id)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(\"save path:\", save_path)\n",
    "\n",
    "# import sys\n",
    "# tempstdout, tempstderr = sys.stdout, sys.stderr\n",
    "# sys.stdout = sys.stderr = open(save_path+'.out', 'a')\n",
    "# job_id = int(os.environ['SLURM_ARRAY_JOB_ID'])\n",
    "# print(\"SLURM_ARRAY_JOB_ID:\", job_id)\n",
    "# print(\"SLURM_ARRAY_TASK_ID:\", task_id)\n",
    "# print(\"jax_enable_x64:\", jconfig.read(\"jax_enable_x64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CONFIG\n",
      "{'a_lpt': 0.5,\n",
      " 'a_obs': 0.5,\n",
      " 'box_shape': array([320., 320., 320.]),\n",
      " 'gxy_density': 0.001,\n",
      " 'latents': {'Omega_m': {'group': 'cosmo',\n",
      "                         'high': 1.0,\n",
      "                         'label': '{\\\\Omega}_m',\n",
      "                         'loc': 0.3111,\n",
      "                         'low': 0.05,\n",
      "                         'scale': 0.2},\n",
      "             'b1': {'group': 'bias',\n",
      "                    'label': '{b}_1',\n",
      "                    'loc': 1.0,\n",
      "                    'scale': 0.5},\n",
      "             'b2': {'group': 'bias',\n",
      "                    'label': '{b}_2',\n",
      "                    'loc': 0.0,\n",
      "                    'scale': 2.0},\n",
      "             'bn2': {'group': 'bias',\n",
      "                     'label': '{b}_{\\\\nabla^2}',\n",
      "                     'loc': 0.0,\n",
      "                     'scale': 2.0},\n",
      "             'bs2': {'group': 'bias',\n",
      "                     'label': '{b}_{s^2}',\n",
      "                     'loc': 0.0,\n",
      "                     'scale': 2.0},\n",
      "             'init_mesh': {'group': 'init',\n",
      "                           'label': '{\\\\delta}_L'},\n",
      "             'sigma8': {'group': 'cosmo',\n",
      "                        'label': '{\\\\sigma}_8',\n",
      "                        'loc': 0.8102,\n",
      "                        'low': 0.0,\n",
      "                        'scale': 0.2}},\n",
      " 'los': array([0., 0., 1.]),\n",
      " 'lpt_order': 1,\n",
      " 'mesh_shape': array([64, 64, 64]),\n",
      " 'nbody_steps': 5,\n",
      " 'obs': 'field',\n",
      " 'precond': 5,\n",
      " 'snapshots': None}\n",
      "\n",
      "# INFOS\n",
      "cell_shape:     [5.0, 5.0, 5.0] Mpc/h\n",
      "k_funda:        0.01963 h/Mpc\n",
      "k_nyquist:      0.62832 h/Mpc\n",
      "mean_gxy_count: 0.125 gxy/cell\n",
      "\n",
      "{'sampler': 'NUTS', 'target_accept_prob': 0.65, 'n_samples': 64, 'max_tree_depth': 10, 'n_runs': 20, 'n_chains': 4}\n",
      "Loading truth from /feynman/home/dphp/hs276503/scratch/pickles/m64_b320.0_al0.5_ao0.5_lo1_pc5_obfield/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 19:21:25.445927: W external/xla/xla/service/gpu/nvptx_compiler.cc:742] The NVIDIA driver's CUDA version is 11.5 which is older than the ptxas CUDA version (11.8.89). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(mcmc_config)\n",
    "# model.render()\n",
    "\n",
    "if not os.path.exists(save_dir+\"truth.p\"):\n",
    "    # Predict and save fiducial\n",
    "    truth = {'Omega_m': 0.31, \n",
    "            'sigma8': 0.81, \n",
    "            'b1': 1.,\n",
    "            'b2':0., \n",
    "            'bs2':0., \n",
    "            'bn2': 0.}\n",
    "\n",
    "    model.reset()\n",
    "    truth = model.predict(samples=truth, hide_base=False, hide_samp=False, frombase=True)\n",
    "    \n",
    "    print(f\"Saving model and truth at {save_dir}\")\n",
    "    model.save(save_dir+\"model.p\")    \n",
    "    pdump(truth, save_dir+\"truth.p\")\n",
    "else:\n",
    "    print(f\"Loading truth from {save_dir}\")\n",
    "    truth = pload(save_dir+\"truth.p\")\n",
    "\n",
    "model.condition({'obs': truth['obs']})\n",
    "model.delta_obs = truth['obs'] - 1\n",
    "model.block()\n",
    "# model.condition({'obs': truth['obs'], 'b1': truth['b1'], 'b2': truth['b2'], 'bs2': truth['bs2'], 'bn2': truth['bn2']}, frombase=True)\n",
    "# model.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS, HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_run = True\n",
    "if continue_run:\n",
    "    model.reset()\n",
    "    model.condition({'obs': truth['obs']})\n",
    "    model.block()\n",
    "else:\n",
    "    model.reset()\n",
    "    model.condition({'obs': truth['obs']} | model.prior_loc, frombase=True)\n",
    "    model.block()\n",
    "\n",
    "    mcmc = get_init_mcmc(model.model, mcmc_config['n_chains'])    \n",
    "    init_params_ = jit(vmap(model.init_model))(jr.split(jr.key(45), mcmc.num_chains))\n",
    "    # init_params_ = model.predict(45, samples=mcmc.num_chains, hide_samp=False)\n",
    "    \n",
    "    if not os.path.exists(save_path + \"_init_last_state.p\"):\n",
    "        print(\"# Warmupping...\")\n",
    "        init_mesh_ = {k: init_params_[k] for k in ['init_mesh_']} # NOTE: !!!!!!!\n",
    "        mcmc = sample_and_save(mcmc, save_path+'_init', 0, 0, extra_fields=['num_steps'], init_params=init_mesh_)\n",
    "        ils = mcmc.last_state.z\n",
    "    else:\n",
    "        print(\"# Loading init_last_state\")\n",
    "        ils = pload(save_path + \"_init_last_state.p\").z\n",
    "    \n",
    "    # ils = {k: jnp.broadcast_to(v, (mcmc_config['n_chains'], *jnp.shape(v))) for k, v in truth.items()}\n",
    "    # ils = {k+'_': ils[k+'_'] for k in ['Omega_m','sigma8','b1','b2','bs2','bn2','init_mesh']}\n",
    "\n",
    "\n",
    "    ################\n",
    "    from montecosmo.plot import plot_pow, plot_powtranscoh, plot_coh\n",
    "    mesh0 = jnp.fft.irfftn(truth['init_mesh'])\n",
    "    kptcs__ = vmap(lambda x: model.powtranscoh(mesh0, model.reparam(x, fourier=False)['init_mesh']))(init_params_)\n",
    "    kptcs_ = vmap(lambda x: model.powtranscoh(mesh0, model.reparam(x, fourier=False)['init_mesh']))(init_params_ | ils)\n",
    "    kpk0 = model.spectrum(mesh0)\n",
    "    kptc_obs = model.powtranscoh(mesh0, truth['obs'] - 1)\n",
    "    kpkobs = model.spectrum(truth['obs']-1)\n",
    "    \n",
    "    print(ils.keys(), init_params_.keys())\n",
    "\n",
    "    mse__ = jnp.mean((vmap(lambda x: model.reparam(x, fourier=False))(init_params_)['init_mesh']  - mesh0)**2, axis=(1,2,3))\n",
    "    mse_ = jnp.mean((vmap(lambda x: model.reparam(x, fourier=False))(init_params_ | ils)['init_mesh']  - mesh0)**2, axis=(1,2,3))\n",
    "    print(\"MSEs:\", mse_, mse_)\n",
    "\n",
    "    prob = 0.95\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plot_powtranscoh(*jnp.median(jnp.stack(kptcs__), 1), label='init')\n",
    "    plot_powtranscoh(*kptcs__, fill=prob)\n",
    "    plot_powtranscoh(*jnp.median(jnp.stack(kptcs_), 1), label='warm')\n",
    "    plot_powtranscoh(*kptcs_, fill=prob)\n",
    "    plt.subplot(131)\n",
    "    plot_pow(*kpk0, 'k', label='true')\n",
    "    plot_pow(*kpkobs, ':', c='grey', label='obs')\n",
    "    plt.legend()\n",
    "    plt.subplot(133)\n",
    "    plot_coh(kptc_obs[0], kptc_obs[-1], ':', c='grey', label='obs')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir+f'init_glin_{task_id}.png')\n",
    "    # plt.savefig(f'init_glin_{task_id}.png')\n",
    "\n",
    "    last_state = pload(save_path + \"_init_last_state.p\")\n",
    "    print(\"mean_acc_prob:\", last_state.mean_accept_prob, \n",
    "        \"\\nss:\", last_state.adapt_state.step_size, \n",
    "        \"\\nmm_sqrt:\", last_state.adapt_state.mass_matrix_sqrt)\n",
    "    ################    \n",
    "    \n",
    "    init_params_ |= ils\n",
    "    # init_params_ |= mcmc.last_state.z\n",
    "    print(init_params_.keys())\n",
    "    model.reset()\n",
    "    model.condition({'obs': truth['obs']})\n",
    "    # init_params_ = {k:v for k,v in init_params_.items() if k in ['Omega_m_', 'sigma8_']} | ils\n",
    "    # model.condition({'obs': truth['obs'], 'b1': truth['b1'], 'b2': truth['b2'], 'bs2': truth['bs2'], 'bn2': truth['bn2']}, frombase=True)\n",
    "    model.block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool=\n",
      "\n",
      "run 7/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/feynman/work/dphp/hs276503/envs/montenvtest3/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest3/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "/feynman/work/dphp/hs276503/envs/montenvtest3/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]/feynman/work/dphp/hs276503/envs/montenvtest3/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n",
      "sample: 100%|██████████| 64/64 [13:23<00:00, 12.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 8/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 64/64 [13:05<00:00, 12.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 9/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 64/64 [13:05<00:00, 12.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 10/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 64/64 [13:04<00:00, 12.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 11/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 64/64 [13:04<00:00, 12.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 12/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 64/64 [13:06<00:00, 12.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 13/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 64/64 [13:04<00:00, 12.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 14/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample:  50%|█████     | 32/64 [06:33<06:33, 12.30s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "if mcmc_config['sampler'] in ['NUTS', 'HMC']:\n",
    "    mcmc = get_mcmc(model.model, mcmc_config)\n",
    "    if continue_run:\n",
    "        print(f\"{jnp.result_type(True)=}\") # HACK: why is it working?!!\n",
    "        mcmc.num_warmup = 0\n",
    "        mcmc.post_warmup_state = pload(save_path + \"_last_state.p\")\n",
    "        start = 7\n",
    "        end = start + mcmc_config['n_runs'] - 1\n",
    "        mcmc_runned = sample_and_save(mcmc, save_path, start, end, rng=43, extra_fields=['num_steps'])\n",
    "\n",
    "    else:\n",
    "        mcmc_runned = sample_and_save(mcmc, save_path, 0, mcmc_config['n_runs'], extra_fields=['num_steps'], init_params=init_params_)\n",
    "\n",
    "elif mcmc_config['sampler'] == 'NUTSWG':\n",
    "    from montecosmo.samplers import nutswg_init, get_nutswg_warm, get_nutswg_run\n",
    "    n_samples, n_runs, n_chains = mcmc_config['n_samples'], mcmc_config['n_runs'], mcmc_config['n_chains']\n",
    "\n",
    "    step_fn, init_fn, conf, init_state_fn = nutswg_init(model.logpdf)\n",
    "\n",
    "    # warmup_fn = jit(vmap(get_nutswg_warm(model.logpdf, conf, mcmc_config['n_samples'], progress_bar=False)))\n",
    "    # state = jit(vmap(init_state_fn))(init_params_)\n",
    "\n",
    "    # samples, infos, state, conf = warmup_fn(jr.split(jr.key(43), n_chains), state)\n",
    "    # print(\"conf:\", conf,\n",
    "    #         \"\\n\\ninfos:\", infos, '\\n#################\\n')\n",
    "    # jnp.savez(save_path+f\"_{0}.npz\", **samples | {k:infos[k] for k in ['n_evals']})\n",
    "    # pdump(state, save_path+f\"_last_state.p\")\n",
    "    # pdump(conf, save_path+'_conf.p'), pdump(tree.map(jnp.mean, infos), save_path+'_infos.p')\n",
    "\n",
    "    conf = pload(save_path+'_conf.p')\n",
    "    state = pload(save_path+'_last_state.p')\n",
    "    \n",
    "    run_fn = jit(vmap(get_nutswg_run(model.logpdf, step_fn, init_fn, n_samples, progress_bar=False)))\n",
    "    start = 1 ######\n",
    "    end = start + n_runs - 1\n",
    "    key = jr.key(42)\n",
    "    for i_run in tqdm(range(start, end+1)):\n",
    "        print(f\"run {i_run}/{end}\")\n",
    "        key, run_key = jr.split(key, 2)\n",
    "        samples, infos, state = run_fn(jr.split(run_key, n_chains), state, conf)\n",
    "        print(\"infos:\", tree.map(lambda x: jnp.mean(x, 1), infos))\n",
    "        jnp.savez(save_path+f\"_{i_run}.npz\", **samples | {k:infos[k] for k in ['n_evals']})\n",
    "        pdump(state, save_path+f\"_last_state.p\")\n",
    "\n",
    "elif mcmc_config['sampler'] == 'MCLMC':\n",
    "    from montecosmo.samplers import get_mclmc_warmup, get_mclmc_run\n",
    "\n",
    "    config = None\n",
    "    # config = {'L':256., 'step_size': 2.,} # 256, 2 for 32^3\n",
    "    # config = {'L':193, 'step_size': 45,} # 64^3\n",
    "    # config = {'L':550, 'step_size': 30,} # 64^3 norsdb fOc a=.5\n",
    "    # config = {'L':500, 'step_size': 10,} # 64^3 norsdb\n",
    "    # config = {'L':450, 'step_size': 3,} # 64^3 a=.5\n",
    "    config = {'L':500, 'step_size': 3,} # 64, 128^3 a=.5\n",
    "\n",
    "    warmup_fn = jit(vmap(get_mclmc_warmup(model.logpdf, n_samples=4096, config=config)))\n",
    "    state, config = warmup_fn(jr.split(jr.key(43), mcmc_config['n_chains']), init_params_)\n",
    "    print(config)\n",
    "    # pdump(state, save_path+f\"_last_state.p\")\n",
    "    # pdump(config, save_path+f\"_conf.p\")\n",
    "\n",
    "    # state = pload(save_path+f\"_last_state.p\")\n",
    "    # config = pload(save_path+f\"_conf.p\")\n",
    "    n_samples, n_runs, n_chains = mcmc_config['n_samples'], mcmc_config['n_runs'], mcmc_config['n_chains']\n",
    "\n",
    "    thinning = 128\n",
    "    run_fn = jit(vmap(get_mclmc_run(model.logpdf, n_samples, thinning=thinning, progress_bar=False)))\n",
    "\n",
    "    start = 1 ######\n",
    "    end = start + n_runs - 1\n",
    "    key = jr.key(42)\n",
    "    for i_run in tqdm(range(start, n_runs + start)):\n",
    "        print(f\"run {i_run}/{n_runs}\")\n",
    "        key, run_key = jr.split(key, 2)\n",
    "        state, samples, info = run_fn(jr.split(run_key, n_chains), state, config)\n",
    "        \n",
    "        info = tree.map(lambda x: jnp.mean(x**2, 1), info)\n",
    "        print(info, \"\\nmean square energy fluctation per dim:\", info.energy_change / model.mesh_shape.astype(float).prod(), '\\n')\n",
    "\n",
    "        jnp.savez(save_path+f\"_{i_run}.npz\", **samples)\n",
    "        pdump(state, save_path+f\"_last_state.p\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
