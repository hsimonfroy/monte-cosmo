{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "Infer from a cosmological model via MCMC samplers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='1.' # NOTE: jax preallocates GPU (default 75%)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax import numpy as jnp, random as jr, jit, vmap, grad, debug, tree\n",
    "\n",
    "from functools import partial\n",
    "from getdist import plots\n",
    "from numpyro import infer\n",
    "\n",
    "# %matplotlib inline\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from montecosmo.model import FieldLevelModel, default_config\n",
    "from montecosmo.utils import pdump, pload\n",
    "from montecosmo.mcbench import sample_and_save\n",
    "\n",
    "# import mlflow\n",
    "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8081\")\n",
    "# mlflow.set_experiment(\"infer\")\n",
    "# !jupyter nbconvert --to script ./src/montecosmo/tests/infer_model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config and fiduc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_dir(**kwargs):\n",
    "    # dir = os.path.expanduser(\"~/scratch/pickles/\")\n",
    "    dir = os.path.expanduser(\"/lustre/fsn1/projects/rech/fvg/uvs19wt/pickles/\")\n",
    "\n",
    "    dir += f\"m{kwargs['mesh_shape'][0]:d}_b{kwargs['box_shape'][0]:.1f}\"\n",
    "    dir += f\"_al{kwargs['a_lpt']:.1f}_ao{kwargs['a_obs']:.1f}_lo{kwargs['lpt_order']:d}_pc{kwargs['precond']:d}_ob{kwargs['obs']}/\"\n",
    "    return dir\n",
    "\n",
    "# config = {\n",
    "#           'mesh_shape':3 * (64,),\n",
    "#           'box_shape':3 * (320.,),\n",
    "#           'a_lpt':0.1,\n",
    "#           'a_obs':0.5,\n",
    "#           'lpt_order':1,\n",
    "#           'precond':1,\n",
    "#           'obs':'mesh'\n",
    "#           }\n",
    "# target_accept_prob = 0.65\n",
    "# save_dir = get_save_dir(**config)\n",
    "\n",
    "# sampler = \"NUTS\"\n",
    "# n_samples, max_tree_depth, n_runs, n_chains = 64, 10, 10, 8\n",
    "# save_path = save_dir + f\"s{sampler}_nc{n_chains:d}_ns{n_samples:d}_mt{max_tree_depth:d}_ta{target_accept_prob}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# def create_parser():\n",
    "#     parser = argparse.ArgumentParser(description='Parse configuration parameters.')\n",
    "#     parser.add_argument('-m', '--mesh_length', type=int, help='Mesh length')\n",
    "#     parser.add_argument('-b', '--box_length', type=float, help='Box length', default=None)\n",
    "#     parser.add_argument('-al', '--a_lpt', type=float, help='a lpt', default=0.1)\n",
    "#     parser.add_argument('-ao', '--a_obs', type=float, help='a obs', default=0.5)\n",
    "#     parser.add_argument('-lo', '--lpt_order', type=int, help='lpt order')\n",
    "#     parser.add_argument('-pc', '--precond', type=int, help='preconditioning')\n",
    "#     parser.add_argument('-o', '--obs', type=str, help='observable type', default='mesh')\n",
    "\n",
    "#     parser.add_argument('-ta', '--target_accept_prob', type=float, help='target rate', default=0.65)\n",
    "#     # parser.add_argument('-sd', '--save_dir', type=str, help='save directory')\n",
    "#     return parser\n",
    "\n",
    "# parser = create_parser()\n",
    "# args = parser.parse_args()\n",
    "\n",
    "class ParseSlurmId():\n",
    "    def __init__(self, id):\n",
    "        self.id = str(id)\n",
    "\n",
    "        dic = {}\n",
    "        dic['mesh_length'] = [32,64,128]\n",
    "        dic['lpt_order'] = [0,1,2]\n",
    "        dic['precond'] = [0,1,2,3]\n",
    "        dic['target_accept_prob'] = [0.65, 0.8]\n",
    "\n",
    "        dic['box_length'] = [None]\n",
    "        dic['a_lpt'] = [0.1]\n",
    "        dic['a_obs'] = [0.5]\n",
    "        dic['obs'] = ['mesh']\n",
    "        \n",
    "        for i, (k, v) in enumerate(dic.items()):\n",
    "            if i < len(self.id):\n",
    "                setattr(self, k, v[int(self.id[i])])\n",
    "            else:\n",
    "                setattr(self, k, v[0])\n",
    "\n",
    "task_id = int(os.environ['SLURM_ARRAY_TASK_ID'])\n",
    "args = ParseSlurmId(task_id)\n",
    "\n",
    "config = {\n",
    "          'mesh_shape':3 * (args.mesh_length,),\n",
    "          'box_shape':3 * (args.box_length if args.box_length is not None else 5 * args.mesh_length,), \n",
    "          'a_lpt':args.a_obs if args.lpt_order > 0 else args.a_lpt,\n",
    "          'a_obs':args.a_obs,\n",
    "          'lpt_order':1 if args.lpt_order==1 else 2, # 2lpt + pm for 0\n",
    "          'precond':args.precond,\n",
    "          'obs':args.obs\n",
    "          }\n",
    "target_accept_prob = args.target_accept_prob\n",
    "save_dir = get_save_dir(**config)\n",
    "\n",
    "sampler = \"NUTS\"\n",
    "n_samples, max_tree_depth, n_runs, n_chains = 64, 10, 10, 8\n",
    "save_path = save_dir + f\"s{sampler}_nc{n_chains:d}_ns{n_samples:d}_mt{max_tree_depth:d}_ta{target_accept_prob}\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "import sys\n",
    "tempstdout = sys.stdout\n",
    "tempstderr = sys.stderr\n",
    "sys.stdout = open(save_path+'.out', 'a')\n",
    "sys.stderr = open(save_path+'.out', 'a')\n",
    "# sys.stdout = tempstdout\n",
    "# sys.stderr = tempstderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CONFIG\n",
      "{'a_lpt': 0.1,\n",
      " 'a_obs': 0.5,\n",
      " 'box_shape': array([320., 320., 320.]),\n",
      " 'gxy_density': 0.001,\n",
      " 'latents': {'Omega_m': {'group': 'cosmo',\n",
      "                         'high': 1.0,\n",
      "                         'label': '{\\\\Omega}_m',\n",
      "                         'loc': 0.3111,\n",
      "                         'low': 0.05,\n",
      "                         'scale': 0.2},\n",
      "             'b1': {'group': 'bias',\n",
      "                    'label': '{b}_1',\n",
      "                    'loc': 1.0,\n",
      "                    'scale': 0.5},\n",
      "             'b2': {'group': 'bias',\n",
      "                    'label': '{b}_2',\n",
      "                    'loc': 0.0,\n",
      "                    'scale': 2.0},\n",
      "             'bn2': {'group': 'bias',\n",
      "                     'label': '{b}_{\\\\nabla^2}',\n",
      "                     'loc': 0.0,\n",
      "                     'scale': 2.0},\n",
      "             'bs2': {'group': 'bias',\n",
      "                     'label': '{b}_{s^2}',\n",
      "                     'loc': 0.0,\n",
      "                     'scale': 2.0},\n",
      "             'init_mesh': {'group': 'init',\n",
      "                           'label': '{\\\\delta}_L'},\n",
      "             'sigma8': {'group': 'cosmo',\n",
      "                        'label': '{\\\\sigma}_8',\n",
      "                        'loc': 0.8102,\n",
      "                        'low': 0.0,\n",
      "                        'scale': 0.2}},\n",
      " 'lpt_order': 1,\n",
      " 'mesh_shape': array([64, 64, 64]),\n",
      " 'obs': 'mesh',\n",
      " 'precond': 1,\n",
      " 'snapshots': None}\n",
      "\n",
      "# INFOS\n",
      "cell_shape:     [5.0, 5.0, 5.0] Mpc/h\n",
      "dk:             0.01963 h/Mpc\n",
      "k_nyquist:      0.62832 h/Mpc\n",
      "mean_gxy_count: 0.125 gxy/cell\n",
      "\n",
      "Loading truth from /feynman/home/dphp/hs276503/scratch/pickles/m64_b320.0_al0.1_ao0.5_lo1_pc1_obmesh/\n"
     ]
    }
   ],
   "source": [
    "model = FieldLevelModel(**default_config | config)\n",
    "print(model)\n",
    "# model.render()\n",
    "\n",
    "if not os.path.exists(save_dir+\"truth.p\"):\n",
    "    # Predict and save fiducial\n",
    "    truth = {'Omega_m': 0.31, \n",
    "            'sigma8': 0.81, \n",
    "            'b1': 1., \n",
    "            'b2':0., \n",
    "            'bs2':0., \n",
    "            'bn2': 0.}\n",
    "\n",
    "    model.reset()\n",
    "    truth = model.predict(samples=truth, hide_base=False, frombase=True)\n",
    "    \n",
    "    print(f\"Saving model and truth at {save_dir}\")\n",
    "    model.save(save_dir)    \n",
    "    pdump(truth, save_dir+\"truth.p\")\n",
    "else:\n",
    "    print(f\"Loading truth from {save_dir}\")\n",
    "    truth = pload(save_dir+\"truth.p\")\n",
    "\n",
    "model.condition({'obs': truth['obs']})\n",
    "model.obs_meshk = truth['obs']\n",
    "model.block()\n",
    "# model.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS, HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mcmc(model, name=\"NUTS\"):\n",
    "    if name == \"NUTS\":\n",
    "        kernel = infer.NUTS(\n",
    "            model=model,\n",
    "            # init_strategy=numpyro.infer.init_to_value(values=fiduc_params)\n",
    "            step_size=1e-3, \n",
    "            max_tree_depth=max_tree_depth,\n",
    "            target_accept_prob=target_accept_prob,)\n",
    "        \n",
    "    elif name == \"HMC\":\n",
    "        kernel = infer.HMC(\n",
    "            model=model,\n",
    "            # init_strategy=numpyro.infer.init_to_value(values=fiduc_params),\n",
    "            step_size=1e-3, \n",
    "            # Rule of thumb (2**max_tree_depth-1)*step_size_NUTS/(2 to 4), compare with default 2pi.\n",
    "            trajectory_length= 1023 * 1e-3 / 4, \n",
    "            target_accept_prob=target_accept_prob,)\n",
    "\n",
    "    mcmc = infer.MCMC(\n",
    "        sampler=kernel,\n",
    "        num_warmup=n_samples,\n",
    "        num_samples=n_samples, # for each run\n",
    "        num_chains=n_chains,\n",
    "        chain_method=\"vectorized\",\n",
    "        progress_bar=True,)\n",
    "    \n",
    "    return mcmc\n",
    "\n",
    "# print(\"mean_acc_prob:\", last_state.mean_accept_prob, \"\\nss:\", last_state.adapt_state.step_size)\n",
    "# invmm = list(last_state.adapt_state.inverse_mass_matrix.values())[0][0]\n",
    "# invmm.min(),invmm.max(),invmm.mean(),invmm.std()\n",
    "\n",
    "# Init params\n",
    "# init_model = model.copy()\n",
    "# init_model.partial(temp=1e-2)\n",
    "# init_params_ = init_model.predict(samples=n_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_run = False\n",
    "if continue_run:\n",
    "    model.reset()\n",
    "    model.condition({'obs': truth['obs']})\n",
    "    model.block()\n",
    "    mcmc = get_mcmc(model.model, name=sampler)\n",
    "\n",
    "    last_state = pload(save_path + \"_last_state.p\")\n",
    "    mcmc.num_warmup = 0\n",
    "    mcmc.post_warmup_state = last_state\n",
    "    init_params_ = last_state.z\n",
    "else:\n",
    "    model.reset()\n",
    "    model.condition({'obs': truth['obs']} | model.prior_loc, frombase=True)\n",
    "    model.block()\n",
    "    mcmc = get_mcmc(model.model, name=sampler)\n",
    "    \n",
    "    init_params_ = jit(vmap(model.init_model))(jr.split(jr.key(43), n_chains))\n",
    "    mcmc = sample_and_save(mcmc, 0, save_path+'_init', extra_fields=['num_steps'], init_params=init_params_)\n",
    "    init_params_ = mcmc.last_state.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_runned = sample_and_save(mcmc, n_runs, save_path, extra_fields=['num_steps'], init_params=init_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
