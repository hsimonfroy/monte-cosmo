{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model annealing\n",
    "Infer a cosmological model via Continuous Tempering Langevin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feynmangpu04.cluster.local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu [cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "!python -c \"import jax; print(jax.default_backend(), jax.devices())\"\n",
    "# !nvidia-smi\n",
    "# numpyro.set_platform(\"gpu\")\n",
    "\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='.33' # NOTE: jax preallocates GPU (default 75%)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap, grad\n",
    "\n",
    "import numpyro\n",
    "from numpyro.handlers import seed, condition, trace\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_experiment(\"Continuous Tempering Langevin\");\n",
    "# mlflow.end_run()\n",
    "# mlflow.start_run(run_name=\"Zee\")\n",
    "# mlflow.log_params({\"ho\":2, \"ha\":np.array([2,3])})\n",
    "# mlflow.log_metrics({\"ho\":2, \"ha\":3}, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run\n",
    "mlflow.start_run()\n",
    "run = mlflow.last_active_run()\n",
    "run.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and simulate fiducial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_config={'mesh_size': array([64, 64, 64]), 'box_size': array([640, 640, 640]), 'scale_factor_lpt': 0.5, 'scale_factor_obs': 0.5, 'galaxy_density': 0.001, 'trace_reparam': True, 'trace_deterministic': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/feynman/work/dphp/hs276503/miniforge3/envs/montecosmoenv/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(arr, dtype)\n"
     ]
    }
   ],
   "source": [
    "from montecosmo.models import pmrsd_model, model_config\n",
    "from montecosmo.utils import get_simulator, get_logp_fn, get_score_fn\n",
    "model_config['scale_factor_lpt'] = 0.5\n",
    "model_config['scale_factor_obs'] = 0.5\n",
    "print(f\"{model_config=}\")\n",
    "\n",
    "model = partial(pmrsd_model, **model_config)\n",
    "\n",
    "# Cosmological parameters\n",
    "cosmo_names = ['Omega_c', 'sigma8']\n",
    "cosmo_labels = [r'\\Omega_c', r'\\sigma_8']\n",
    "cond_params = {var_name+'_base': 0. for var_name in cosmo_names}\n",
    "\n",
    "fiducial_simulator = get_simulator(condition(model, cond_params))\n",
    "fiducial_params = fiducial_simulator(rng_seed=0)\n",
    "fiducial_cosmo_params = {name: fiducial_params[name] for name in cosmo_names}\n",
    "\n",
    "# Condition model\n",
    "obs_names = ['obs_mesh'] # NOTE: Only condition on random sites\n",
    "obs_params = {name: fiducial_params[name] for name in obs_names}\n",
    "observed_model = condition(model, obs_params)\n",
    "logp_fn = get_logp_fn(observed_model)\n",
    "score_fn = get_score_fn(observed_model)\n",
    "\n",
    "# Parameters to initialize samplers on\n",
    "init_names = ['Omega_c', 'sigma8', 'init_mesh', 'b1', 'b2', 'bs', 'bnl'] # NOTE: Only init on random sites\n",
    "init_params = {name+'_base': fiducial_params[name+'_base'] for name in init_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-744184.75, dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_fn(fiducial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-862459.9, dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiducial_params['obs_mesh'] = jnp.zeros((64,64,64))\n",
    "logp_fn(fiducial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-862459.9, dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiducial_params['init_mesh'] = jnp.zeros((64,64,64))\n",
    "logp_fn(fiducial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-612866.44, dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiducial_params['init_mesh_base'] = jnp.zeros((64,64,64))\n",
    "logp_fn(fiducial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffrax import diffeqsolve, ControlTerm, Euler, MultiTerm, ODETerm, SaveAt, VirtualBrownianTree, ReversibleHeun\n",
    "from jax.tree_util import tree_map, tree_flatten\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from jax import  eval_shape\n",
    "\n",
    "t0, t1 = 5, 0.\n",
    "noise = lambda t: t/t0\n",
    "drift = lambda t, y, args: tree_map(lambda x: -0.5 * x, score_fn(y, model_kwargs={'noise':noise(t)}))\n",
    "diffusion = lambda t, y, args: tree_map(lambda x: jnp.ones_like(x), y)\n",
    "solver = Euler()\n",
    "ts = jnp.linspace(t0,t1,100)\n",
    "saveat = SaveAt(ts=ts)\n",
    "\n",
    "sample_shape_struct = eval_shape(lambda x:{name: x[name][0] for name in x.keys()}, samples)\n",
    "\n",
    "@jit\n",
    "@vmap\n",
    "def get_samples(y, seed):\n",
    "  brownian_motion = VirtualBrownianTree(t0, t1, tol=1e-4, shape=sample_shape_struct, key=seed)\n",
    "  terms = MultiTerm(ODETerm(drift), ControlTerm(diffusion, brownian_motion))\n",
    "  return diffeqsolve(terms, solver, t0, t1, dt0=-0.001, y0=y, max_steps=10_000, saveat=saveat).ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
